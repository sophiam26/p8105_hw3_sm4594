---
title: "Data Science Homework #3"
author: "Sophia Miller"
date: "10/6/2019"
output: github_document
---

```{r setupcode, include=FALSE}
library(tidyverse)
library(viridis)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# Problem 1
## *Loading Instacart data*

```{r load_instacart}
library(p8105.datasets)
data("instacart")
```

## *Description of Instacart dataset*

The dataset used here is a cleaned and limited subset of the original Instacart data. Each row in this dataset represents a single product from an Instacart order. There are `r nrow(instacart)` rows and `r ncol(instacart)` columns in the dataset. Each observation has an order identifier (`order_id`), product identifier (`product_id`), and customer identifier (`user_id`). Key variables include `reordered`, which indicates  if the product has been ordered by the customer in the past month, `order_dow`, which indicates which day of the week the order was placed, `days_since_prior_order`, which indicates the number of days since the customer's last order, and `product_name`, which is the name of the product ordered. For example, the mean number of days between orders is `r round(mean(pull(instacart, days_since_prior_order)), 0)`, the mean hour of the day during which products from the ice cream aisle were ordered is `r round(mean(pull(filter(instacart, aisle == "ice cream ice"), order_hour_of_day)), 0)` (2:00PM), and the total number of products ordered from the "specialty cheeses" aisle in the dataset is `r nrow(filter(instacart, aisle == "specialty cheeses"))`.

## *Exploratory analysis of Instacart dataset*

There are `r nrow(distinct(instacart, aisle))` aisles in the dataset, and the most items are ordered from the "`r names(which.max(table(pull(instacart, aisle))))" aisle.

The following plot shows the numbers of items ordered from each aisle (limited to aisles with more than 10,000 items ordered):

```{r aisle_plot}
instacart %>% 
  group_by(aisle) %>% 
  summarize(
    n_items_ordered = n()) %>% 
  mutate(aisle = reorder(aisle, n_items_ordered)) %>% 
  filter(n_items_ordered > 10000) %>% 
  ggplot(aes(x = aisle, y = n_items_ordered)) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + geom_col() + ggtitle("Figure 1. Number of items ordered per aisle") + theme(plot.title = element_text(hjust = 0.5))
```

As we can see from the plot above, the "fresh vegetables" and "fresh fruits" aisles are the most popular aisles, with approximately 150,000 items ordered from each. The least popular aisles are the "butter" and "oils vinegars" aisles.

The following table shows the three most popular items in the "baking ingredients", "dog food care", and "packaged fruits and vegetables" aisles:

```{r popular_items}
instacart %>% 
  group_by(product_name, aisle) %>%
  summarize(
    n_items_ordered = n()
    ) %>% 
  group_by(aisle) %>% 
  filter(
    aisle %in% c("baking ingredients","dog food care", "packaged vegetables fruits"),
    min_rank(desc(n_items_ordered)) < 4) %>% 
  arrange(n_items_ordered, aisle) %>% 
  knitr::kable(format = 'pandoc', caption = "Table 1. Most popular items by aisle")
```

As we can see from the table above, the most popular item ordered from the "dog food" aisle is snack sticks chicken & rice recipe dog treats, the most popular item ordered from the "baking ingredients" aisle is light brown sugar, and the most popular item ordered from the "packaged fruits and vegetables" aisle is organic baby spinach.

The following table shows the mean time of day that pink lady apples and coffee ice cream were ordered on each day of the week:

```{r time_of_day_table}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  mutate(order_dow = as.factor(order_dow)) %>% 
  arrange(order_dow) %>% 
  mutate(Day = recode(order_dow, '0' = "Sunday", '1' = "Monday", '2' = "Tuesday", '3' = "Wednesday", '4' = "Thursday", '5' = "Friday", '6' = "Saturday")) %>% 
  group_by(product_name, Day) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = product_name,
    values_from = mean_hour) %>% 
  knitr::kable(format = 'pandoc', caption = "Table 2. Mean hour of day of item order, by day of week", digits = 0)

## convert hour to time variable
```

As we can see from the table above, both coffee ice cream and pink lady apples tend to be ordered in the afternoon, regardless of the day of the week. On average, coffee ice cream is ordered between 12:00PM and 3:00PM, while pink lady apples are ordered between 11:00AM and 2:00PM.

# Problem 2
## *Loading BRFSS data*

```{r load_brfss}
library(p8105.datasets)
data("brfss_smart2010") 
```

## *Cleaning BRFSS data*

```{r clean_brfss}
brfss_data = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  separate(locationdesc, c("state", "county")) %>% 
  filter(topic == "Overall Health") %>% 
  mutate(response = 
           factor(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>% 
  select(-locationabbr)
```

## *Exploratory data analysis of BRFSS data*

Here, we can see which states were observed at 7 or more locations in 2002 and 2010: 

```{r common_states}
brfss_data %>% 
  filter(year %in% c("2002", "2010")) %>% 
  group_by(state, year) %>% 
  summarize(
  n_counties = n_distinct(county)) %>% 
  filter(n_counties >= 7) %>% 
  arrange(year) %>% 
knitr::kable(format = 'pandoc', caption = "Table 3. States observed in 7 or more counties, 2002 and 2010")
```

According to the table above, there were 5 states observed at 7 or more locations in 2002, and 14 states observed at 7 or more locations in 2010. In 2002, the state observed at the most locations was Pennsylvania. In 2010, the state observed at the most locations was Florida. 

Here we are creating a subset of the BRFSS dataset that is limited to only `Excellent` responses, and contains the year and state variables as well as a new variable indicating if the day of observation is during the week or weekend:

```{r brfss_subset}
brfss_subset = brfss_data %>% 
  filter(response == "Excellent") %>% 
    select(year, state, data_value) %>%
  group_by(state, year) %>%
  mutate(mean_data_value = mean(data_value, na.rm = TRUE)) %>%
  select(-data_value) %>% 
  distinct(.keep_all = TRUE)

ggplot(brfss_subset, aes(x = year, y = mean_data_value)) + geom_line(aes(group = state, color = state)) + ggtitle("Figure 2. Average data value across locations within each state") + theme(plot.title = element_text(hjust = 0.5)) + theme(legend.text = element_text(size = 7))
```

Two-panel plot

```{r brfss_plot}
brfss_data %>% 
  filter(year %in% c("2006", "2010")) %>%
  select(year, state, response, data_value) %>%
  ggplot(aes(x = response, y = data_value)) + geom_boxplot(aes(color = response)) + facet_grid(~year)
```

# Problem 3
## Load and clean accelerometer data

```{r accel}
accel_data = read_csv(file = "./data/accel_data.csv") %>% 
  janitor::clean_names() %>%
   pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    values_to = "activity") %>% 
  mutate(
    weekday_vs_weekend = if_else(day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"), "weekday", day), 
    weekday_vs_weekend = if_else(weekday_vs_weekend %in% c("Saturday", "Sunday"), "weekend", weekday_vs_weekend),
    day =  factor(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")),
    ) %>%
separate(minute, c("activity_value", "minute")) %>% 
select(-activity_value) %>% 
  mutate(minute = as.numeric(minute))
```

# Aggregating total activity across each day

```{r total_activity}
accel_data %>% 
  group_by(week, day) %>% 
  mutate(total_activity = sum(activity)) %>% 
  select(week, day, total_activity) %>% 
  distinct(.keep_all = TRUE) %>% 
  arrange(week, day) %>% 
  knitr::kable(format = 'pandoc', caption = "Table 5. Total Activity by Day and Week")

#which variables should be included in addition to total_activity? Should we just observe trends or do an analysis?
```

# Time plot

```{r 24hr_activity_plot}
accel_data %>%
  ggplot(aes(x = minute, y = activity)) + geom_point(aes(group = day, color = day), alpha = 0.4) + geom_smooth(aes(group = day, color = day, se = FALSE))
```







